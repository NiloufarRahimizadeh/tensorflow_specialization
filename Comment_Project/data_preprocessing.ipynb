{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c153ef88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text (comment)</th>\n",
       "      <th>Spam or ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>یه مشت لات و لوت جمع کردید تو این اتاق فرار و ...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سناریو اصلا خوب نبود و برای ما نصفه تموم شد - ...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>رفتار پرسنل مناسب نبود\\n  عدم اگاهی رسانی دقیق...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>😡😡😡هشدار این یک کلاه برداری علنی است😡😡😡\\nخونه ...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اتاق فرار خوبی بود اما نه به اندازه کامنت ها ق...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text (comment) Spam or ham \n",
       "0  یه مشت لات و لوت جمع کردید تو این اتاق فرار و ...         Spam\n",
       "1  سناریو اصلا خوب نبود و برای ما نصفه تموم شد - ...         Spam\n",
       "2  رفتار پرسنل مناسب نبود\\n  عدم اگاهی رسانی دقیق...         Spam\n",
       "3  😡😡😡هشدار این یک کلاه برداری علنی است😡😡😡\\nخونه ...         Spam\n",
       "4  اتاق فرار خوبی بود اما نه به اندازه کامنت ها ق...         Spam"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "data_path = '/Users/niloufar/Desktop/DeepLearning/tf_specialization/comment/'\n",
    "data1 = 'spam_or_not1.xlsx'\n",
    "data2 = 'spam_or_not2.xlsx'\n",
    "data3 = 'spam_or_not3.xlsx'\n",
    "df1 = pd.read_excel(data_path + data1)\n",
    "df2 = pd.read_excel(data_path + data2)\n",
    "df3 = pd.read_excel(data_path + data3)\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "df = df.drop(['ID', df.columns[3]], axis=1)\n",
    "# df.iloc[995:1005, :]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentence):\n",
    "    stopwords = ['را', 'به', 'و', 'از', 'که']\n",
    "    words = sentence.split()\n",
    "    results_words = [word for word in words if word not in stopwords]\n",
    "    sentence = ' '.join(results_words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95990b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords(\"پدر سگ را به درخت بست.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b77f11",
   "metadata": {},
   "source": [
    "### Reading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1878b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_from_file(file):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    for i, j in zip(df[df.columns[0]], df[df.columns[1]]):\n",
    "        sentences.append(remove_stopwords(i))\n",
    "        labels.append(j)\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7457fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, labels = parse_data_from_file(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(sentences)} sentences in the dataset.\\n\")\n",
    "print(f\"First sentence has {len(sentences[0].split())} words (after removing stopwords).\\n\")\n",
    "print(f\"There are {len(labels)} labels in the dataset.\\n\")\n",
    "print(f\"The first 5 labels are {labels[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a3b18",
   "metadata": {},
   "source": [
    "### Using the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e786310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tokenizer(sentences):\n",
    "    tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34391a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = fit_tokenizer(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(f\"Vocabulary contains {len(word_index)} words\\n\")\n",
    "print(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_sequences(tokenizer, sentences):\n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    padded_sequences = pad_sequences(sequences, padding='post')\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = get_padded_sequences(tokenizer, sentences)\n",
    "print(f\"First padded sequence looks like this: \\n\\n{padded_sequences[0]}\\n\")\n",
    "print(f\"Numpy array of all sequences has shape: {padded_sequences.shape}\\n\")\n",
    "print(f\"This means there are {padded_sequences.shape[0]} sequences in total and each one has a size of {padded_sequences.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_labels(labels):\n",
    "    label_tokenizer = Tokenizer()\n",
    "    label_tokenizer.fit_on_texts(labels)\n",
    "    label_word_index = label_tokenizer.word_index\n",
    "    label_sequences = label_tokenizer.texts_to_sequences(labels)\n",
    "    return label_sequences, label_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56390c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sequences, label_word_index = tokenize_labels(labels)\n",
    "print(f\"Vocabulary of labels looks like this {label_word_index}\\n\")\n",
    "print(f\"First ten sequences {label_sequences[:10]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7383d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269197c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715405de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b7054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf38",
   "language": "python",
   "name": "tf38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
